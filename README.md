MLLM-empowered Multi-agent Collaboration for Outdoor Visual Language Navigation

# Preparations

Tested with Python 3.10<br>
Install packages in requirements.txt<br><br>


# References
Code based on https://github.com/raphael-sch/VELMA <br>
Touchdown splits based on: https://github.com/lil-lab/touchdown  <br>
map2seq splits based on: https://map2seq.schumann.pub  <br>
Panorama images can be downloaded here: https://sites.google.com/view/streetlearn/dataset <br>